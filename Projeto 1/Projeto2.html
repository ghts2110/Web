<!DOCTYPE html>
<html lang="pt-br">

<head>
    <title>Projeto 2</title>
</head>

<body>
    <h3>
        PIBIC
    </h3>

    <p>
        A explicabilidade de um modelo preditivo é crucial para garantir confiança, detecção de viés, compreensão e
        melhoria <br>
        contínua, bem como conformidade regulatória. Ao entender como o modelo toma suas decisões, podemos confiar mais
        <br>
        nele, identificar e corrigir preconceitos nos dados, ajustar o modelo para melhorar seu desempenho e cumprir
        <br>
        regulamentações que exigem transparência nas decisões dos modelos. Em suma, a explicabilidade é como uma janela
        <br>
        que nos permite compreender e confiar nas previsões feitas pelos modelos preditivos.
    </p>

    <br>
    <br>
    <br>
    <br>
    <br>

    <caption> Benefícios da Explicabilidade </caption>
    <ul>
        <li>
            Confiança: Permite aos usuários entender como e por que o modelo toma suas decisões, aumentando a confiança
            <br>
            nas previsões.
        </li>

        <li>
            Detecção de Viés: Facilita a identificação de preconceitos nos dados de treinamento e nas decisões do
            modelo, <br>
            permitindo correções para garantir justiça e imparcialidade.
        </li>

        <li>
            Compreensão e Melhoria: Ajuda na compreensão do problema e do processo de modelagem, permitindo ajustes para
            melhorar <br>
            o desempenho e a eficácia do modelo.
        </li>

        <li>
            Conformidade Regulatória: É fundamental para cumprir regulamentações que exigem transparência nas decisões
            dos <br>
            modelos, especialmente em setores como saúde, finanças e segurança.
        </li>
    </ul>

    <br>
    <br>
    <br>
    <br>
    <br>

    <table border="1">
        <tr>
            <td>Nome</td>
            <td>SHAP (SHapley Additive exPlanations)</td>
            <td>LIME (Local Interpretable Model-agnostic Explanations)</td>
            <td>AMRules (Association Rule-based Model)</td>
            <td>MFCC (Mel-Frequency Cepstral Coefficients)</td>
            <td>Tree Interpreter</td>
        </tr>
        <tr>
            <td>Descrição</td>
            <td>Utiliza a teoria dos jogos para calcular a contribuição de cada variável para a previsão do modelo, 
                 atribuindo um valor Shapley a cada recurso.</td>
            <td>Cria modelos locais simples em torno de instâncias individuais para explicar as previsões do 
                modelo principal, oferecendo interpretações compreensíveis e específicas para cada instância.</td>
            <td>Baseia-se em regras de associação para identificar padrões e relações entre 
                variáveis nos dados, fornecendo explicações intuitivas em termos de regras facilmente compreensíveis.</td>
            <td>Um método específico para explicar modelos de reconhecimento de fala, analisando as 
                características do sinal de áudio em termos de coeficientes cepstrais de frequência melódica.</td>
            <td>Específico para modelos baseados em árvores de decisão, este método ajuda a explicar como cada ramo 
                da árvore contribui para a previsão final, oferecendo uma interpretação intuitiva das decisões do modelo.</td>
        </tr>
    </table>

    <audio src="Portal Still Alive_ Musica Final Traduzida.mp4" controls autoplay>
        Seu navegador não suporta a tag audio. </audio>

    <br>
    <a href="index.html"> voltar a pagina inicial </a>
</body>


</html>